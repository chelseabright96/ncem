{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import squidpy as sq\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data, LightningNodeData\n",
    "import torch_sparse\n",
    "import torch_geometric.nn as geom_nn\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sq.datasets.mibitof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_num</th>\n",
       "      <th>point</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>X1</th>\n",
       "      <th>center_rowcoord</th>\n",
       "      <th>center_colcoord</th>\n",
       "      <th>cell_size</th>\n",
       "      <th>category</th>\n",
       "      <th>donor</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>batch</th>\n",
       "      <th>library_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3034-0</th>\n",
       "      <td>3086</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>60316.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>carcinoma</td>\n",
       "      <td>21d7</td>\n",
       "      <td>Epithelial</td>\n",
       "      <td>0</td>\n",
       "      <td>point23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035-0</th>\n",
       "      <td>3087</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>60317.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>carcinoma</td>\n",
       "      <td>21d7</td>\n",
       "      <td>Epithelial</td>\n",
       "      <td>0</td>\n",
       "      <td>point23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036-0</th>\n",
       "      <td>3088</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>60318.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>carcinoma</td>\n",
       "      <td>21d7</td>\n",
       "      <td>Imm_other</td>\n",
       "      <td>0</td>\n",
       "      <td>point23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3037-0</th>\n",
       "      <td>3089</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>60320.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>carcinoma</td>\n",
       "      <td>21d7</td>\n",
       "      <td>Myeloid_CD11c</td>\n",
       "      <td>0</td>\n",
       "      <td>point23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038-0</th>\n",
       "      <td>3090</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>60322.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>carcinoma</td>\n",
       "      <td>21d7</td>\n",
       "      <td>Myeloid_CD11c</td>\n",
       "      <td>0</td>\n",
       "      <td>point23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47342-2</th>\n",
       "      <td>48953</td>\n",
       "      <td>16</td>\n",
       "      <td>1103</td>\n",
       "      <td>2779.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>carcinoma</td>\n",
       "      <td>90de</td>\n",
       "      <td>Fibroblast</td>\n",
       "      <td>2</td>\n",
       "      <td>point16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47343-2</th>\n",
       "      <td>48954</td>\n",
       "      <td>16</td>\n",
       "      <td>1104</td>\n",
       "      <td>2780.0</td>\n",
       "      <td>814.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>carcinoma</td>\n",
       "      <td>90de</td>\n",
       "      <td>Fibroblast</td>\n",
       "      <td>2</td>\n",
       "      <td>point16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47344-2</th>\n",
       "      <td>48955</td>\n",
       "      <td>16</td>\n",
       "      <td>1105</td>\n",
       "      <td>2781.0</td>\n",
       "      <td>874.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>carcinoma</td>\n",
       "      <td>90de</td>\n",
       "      <td>Imm_other</td>\n",
       "      <td>2</td>\n",
       "      <td>point16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47345-2</th>\n",
       "      <td>48956</td>\n",
       "      <td>16</td>\n",
       "      <td>1106</td>\n",
       "      <td>2782.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>carcinoma</td>\n",
       "      <td>90de</td>\n",
       "      <td>Fibroblast</td>\n",
       "      <td>2</td>\n",
       "      <td>point16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47346-2</th>\n",
       "      <td>48957</td>\n",
       "      <td>16</td>\n",
       "      <td>1107</td>\n",
       "      <td>2783.0</td>\n",
       "      <td>533.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>carcinoma</td>\n",
       "      <td>90de</td>\n",
       "      <td>Fibroblast</td>\n",
       "      <td>2</td>\n",
       "      <td>point16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3309 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         row_num  point  cell_id       X1  center_rowcoord  center_colcoord  \\\n",
       "3034-0      3086     23        2  60316.0            269.0              7.0   \n",
       "3035-0      3087     23        3  60317.0            294.0              6.0   \n",
       "3036-0      3088     23        4  60318.0            338.0              4.0   \n",
       "3037-0      3089     23        6  60320.0            372.0              6.0   \n",
       "3038-0      3090     23        8  60322.0            417.0              5.0   \n",
       "...          ...    ...      ...      ...              ...              ...   \n",
       "47342-2    48953     16     1103   2779.0            143.0           1016.0   \n",
       "47343-2    48954     16     1104   2780.0            814.0           1017.0   \n",
       "47344-2    48955     16     1105   2781.0            874.0           1018.0   \n",
       "47345-2    48956     16     1106   2782.0            257.0           1019.0   \n",
       "47346-2    48957     16     1107   2783.0            533.0           1019.0   \n",
       "\n",
       "         cell_size   category donor        Cluster batch library_id  \n",
       "3034-0       408.0  carcinoma  21d7     Epithelial     0    point23  \n",
       "3035-0       408.0  carcinoma  21d7     Epithelial     0    point23  \n",
       "3036-0       304.0  carcinoma  21d7      Imm_other     0    point23  \n",
       "3037-0       219.0  carcinoma  21d7  Myeloid_CD11c     0    point23  \n",
       "3038-0       303.0  carcinoma  21d7  Myeloid_CD11c     0    point23  \n",
       "...            ...        ...   ...            ...   ...        ...  \n",
       "47342-2      283.0  carcinoma  90de     Fibroblast     2    point16  \n",
       "47343-2      147.0  carcinoma  90de     Fibroblast     2    point16  \n",
       "47344-2      142.0  carcinoma  90de      Imm_other     2    point16  \n",
       "47345-2      108.0  carcinoma  90de     Fibroblast     2    point16  \n",
       "47346-2      111.0  carcinoma  90de     Fibroblast     2    point16  \n",
       "\n",
       "[3309 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset \n",
    "adata = sq.datasets.imc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-24 08:15:36.259186: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-24 08:15:36.259410: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from dataset import HartmannWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HartmannWrapper(\"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'train_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.9/site-packages/torch_geometric/data/storage.py:50\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m[key]\n\u001b[1;32m     51\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.9/site-packages/torch_geometric/data/storage.py:70\u001b[0m, in \u001b[0;36mBaseStorage.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mapping[key]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'train_mask'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb#ch0000004vscode-remote?line=0'>1</a>\u001b[0m dataset[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mtrain_mask\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.9/site-packages/torch_geometric/data/data.py:362\u001b[0m, in \u001b[0;36mData.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_store\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[1;32m    357\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    358\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m\u001b[39m object was created by an older version of PyG. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    359\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIf this error occurred while loading an already existing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    360\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdataset, remove the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mprocessed/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m directory in the dataset\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    361\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mroot folder and try again.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 362\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_store, key)\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.9/site-packages/torch_geometric/data/storage.py:52\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[key]\n\u001b[1;32m     51\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m     53\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'train_mask'"
     ]
    }
   ],
   "source": [
    "dataset[0].train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=58, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = geom_nn.GCNConv(dataset.num_node_features, dataset.y.shape[1])\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNCEM(pl.LightningModule):\n",
    "    def __init__(self, **model_kwargs):\n",
    "        super().__init__()\n",
    "        # Saving hyperparameters\n",
    "        self.save_hyperparameters(model_kwargs)\n",
    "\n",
    "        self.model_mu = GCN(\n",
    "            in_channels=self.hparams.in_channels,\n",
    "            hidden_dims=self.hparams.encoder_hidden_dims,\n",
    "            out_channels=self.hparams.latent_dim,\n",
    "        )\n",
    "\n",
    "        self.model_sigma = GCN(\n",
    "            in_channels=self.hparams.in_channels,\n",
    "            hidden_dims=self.hparams.encoder_hidden_dims,\n",
    "            out_channels=self.hparams.latent_dim,\n",
    "        )\n",
    "\n",
    "        self.loss_module = nn.GaussianNLLLoss(eps=1e-5)\n",
    "\n",
    "        def init_weights(m):\n",
    "            if isinstance(m, geom_nn.GCNConv):\n",
    "                pass\n",
    "                # TODO: how to init weights of GNN's?\n",
    "                # torch.nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                # m.bias.data.fill_(0.01)\n",
    "\n",
    "\n",
    "        self.model_mu.apply(init_weights)\n",
    "        self.model_sigma.apply(init_weights)\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        sigma = self.model_mu(x, edge_index)\n",
    "        mu = self.model_sigma(x, edge_index)\n",
    "        return mu, sigma\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # We use SGD here, but Adam works as well\n",
    "        optimizer = optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=0.05,#self.hparams[\"lr\"],\n",
    "            weight_decay=0#self.hparams[\"weight_decay\"],\n",
    "        )\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, _):\n",
    "        mu, sigma = self.forward(batch)\n",
    "        loss = self.loss_module(mu, batch.y, sigma)\n",
    "        self.log('train_loss', loss, batch_size=batch.batch_size)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, _):\n",
    "        mu, sigma = self.forward(batch)\n",
    "        val_loss = self.loss_module(mu, batch.y, sigma)\n",
    "        val_r2_score = r2_score(batch.y.cpu(), mu.cpu())\n",
    "        self.log('val_r2_score', val_r2_score, batch_size=batch.batch_size, prog_bar=True)\n",
    "        self.log('val_loss', val_loss, batch_size=batch.batch_size, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, _):\n",
    "        mu, sigma = self.forward(batch)\n",
    "        self.log('test_loss', loss, batch_size=batch.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get adjacency matrix\n",
    "sq.gr.spatial_neighbors(adata, coord_type=\"generic\")\n",
    "A=adata.obsp['spatial_connectivities']\n",
    "\n",
    "#Get features of nodes \n",
    "X=adata.obs\n",
    "X=pd.get_dummies(X)\n",
    "X=X.to_numpy()\n",
    "X=torch.tensor(X)\n",
    "\n",
    "#Get labels of nodes\n",
    "Y=adata.X\n",
    "Y=torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Acoo = A.tocoo()\n",
    "A_sparse = torch.sparse.FloatTensor(torch.LongTensor([Acoo.row.tolist(), Acoo.col.tolist()]),\n",
    "                              torch.FloatTensor(Acoo.data)).coalesce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(x=X,edge_index=A_sparse.indices(), y=Y, train_mask=torch.arange(A.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[4668, 11], edge_index=[2, 28008], y=[4668, 34], train_mask=[4668])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.GaussianNLLLoss()\n",
    "input = torch.randn(5, 2, requires_grad=True)\n",
    "target = torch.randn(5, 2)\n",
    "var = torch.ones(5, 2, requires_grad=True) #heteroscedastic\n",
    "output = loss(input, target, var)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = NeighborLoader(\n",
    "    data,\n",
    "    # Sample 30 neighbors for each node for 2 iterations\n",
    "    num_neighbors=[30] * 2,\n",
    "    # Use a batch size of 128 for sampling training nodes\n",
    "    batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning_loader = LightningNodeData(data, data.train_mask, loader='neighbor',\n",
    "                                   num_neighbors=[30] * 2, batch_size=128,\n",
    "                                   num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[292, 11], edge_index=[2, 1254], y=[292, 34], train_mask=[292], batch_size=128)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data ## this is one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(result_dict):\n",
    "    if \"train\" in result_dict:\n",
    "        print(f\"Train loss: {result_dict['train']}\")\n",
    "    if \"val\" in result_dict:\n",
    "        print(f\"Val loss:   {result_dict['val']}\")\n",
    "    print(f\"Test loss:  {result_dict['test']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_node_classifier(cur_dir, model_name, data, **model_kwargs):\n",
    "    pl.seed_everything(42)\n",
    "    node_data_loader = lightning_loader \n",
    "    strategy = pl.strategies.DDPStrategy(find_unused_parameters=False)\n",
    "    '''NeighborLoader(\n",
    "    data,\n",
    "    # Sample 30 neighbors for each node for 2 iterations\n",
    "    num_neighbors=[30] * 2,\n",
    "    # Use a batch size of 128 for sampling training nodes\n",
    "    batch_size=128)'''\n",
    "\n",
    "    CHECKPOINT_PATH = cur_dir + \"checkpoints\"\n",
    "\n",
    "    # Create a PyTorch Lightning trainer with the generation callback\n",
    "    root_dir = os.path.join(CHECKPOINT_PATH, model_name)\n",
    "    os.makedirs(root_dir, exist_ok=True)\n",
    "    trainer = pl.Trainer(strategy=strategy, default_root_dir=root_dir, callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"min\", monitor=\"val_loss\")],\n",
    "                         max_epochs=200,\n",
    "                         progress_bar_refresh_rate=0) # 0 because epoch size is 1\n",
    "\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, f\"{model_name}.ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(\"Found pretrained model, loading...\")\n",
    "        model = NodeLevelGNN.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        pl.seed_everything()\n",
    "        model = NodeLevelGNN(model_name=model_name, c_in=data.x.shape[1], c_out=data.y.shape[1], **model_kwargs)\n",
    "        trainer.fit(model, node_data_loader)\n",
    "        model = NodeLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "\n",
    "    # Test best model on the test set\n",
    "    test_result = trainer.test(model, node_data_loader, verbose=False)\n",
    "    batch = next(iter(node_data_loader))\n",
    "    batch = batch.to(model.device)\n",
    "    train_loss = model.forward(batch, mode=\"train\")\n",
    "    val_loss = model.forward(batch, mode=\"val\")\n",
    "    result = {\"train\": train_loss,\n",
    "              \"val\": val_loss,\n",
    "              \"test\": test_result['test_loss']}\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "`Trainer(strategy='ddp')` or `Trainer(accelerator='ddp')` is not compatible with an interactive environment. Run your code as a script, or choose one of the compatible strategies: Trainer(strategy=None|dp|tpu_spawn). In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb#ch0000011vscode-remote?line=0'>1</a>\u001b[0m cwd\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mgetcwd()\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb#ch0000011vscode-remote?line=1'>2</a>\u001b[0m model, result \u001b[39m=\u001b[39m train_node_classifier(cur_dir\u001b[39m=\u001b[39;49mcwd, model_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mnonlinear NCEM\u001b[39;49m\u001b[39m\"\u001b[39;49m,data\u001b[39m=\u001b[39;49mdata,c_hidden\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,num_layers\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,dp_rate\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb#ch0000011vscode-remote?line=3'>4</a>\u001b[0m print_results(result)\n",
      "\u001b[1;32m/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb Cell 12\u001b[0m in \u001b[0;36mtrain_node_classifier\u001b[0;34m(cur_dir, model_name, data, **model_kwargs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb#ch0000011vscode-remote?line=14'>15</a>\u001b[0m root_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(CHECKPOINT_PATH, model_name)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb#ch0000011vscode-remote?line=15'>16</a>\u001b[0m os\u001b[39m.\u001b[39mmakedirs(root_dir, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb#ch0000011vscode-remote?line=16'>17</a>\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39;49mTrainer(strategy\u001b[39m=\u001b[39;49mstrategy, default_root_dir\u001b[39m=\u001b[39;49mroot_dir, callbacks\u001b[39m=\u001b[39;49m[ModelCheckpoint(save_weights_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmin\u001b[39;49m\u001b[39m\"\u001b[39;49m, monitor\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mval_loss\u001b[39;49m\u001b[39m\"\u001b[39;49m)],\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb#ch0000011vscode-remote?line=17'>18</a>\u001b[0m                      max_epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb#ch0000011vscode-remote?line=18'>19</a>\u001b[0m                      progress_bar_refresh_rate\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m) \u001b[39m# 0 because epoch size is 1\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb#ch0000011vscode-remote?line=21'>22</a>\u001b[0m \u001b[39m# Check whether pretrained model exists. If yes, load it and skip training\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb#ch0000011vscode-remote?line=22'>23</a>\u001b[0m pretrained_filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(CHECKPOINT_PATH, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m.ckpt\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.9/site-packages/pytorch_lightning/utilities/argparse.py:339\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mlist\u001b[39m(env_variables\u001b[39m.\u001b[39mitems()) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mitems()))\n\u001b[1;32m    338\u001b[0m \u001b[39m# all args were already moved to kwargs\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:485\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, logger, checkpoint_callback, enable_checkpointing, callbacks, default_root_dir, gradient_clip_val, gradient_clip_algorithm, process_position, num_nodes, num_processes, devices, gpus, auto_select_gpus, tpu_cores, ipus, log_gpu_memory, progress_bar_refresh_rate, enable_progress_bar, overfit_batches, track_grad_norm, check_val_every_n_epoch, fast_dev_run, accumulate_grad_batches, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, val_check_interval, flush_logs_every_n_steps, log_every_n_steps, accelerator, strategy, sync_batchnorm, precision, enable_model_summary, weights_summary, weights_save_path, num_sanity_val_steps, resume_from_checkpoint, profiler, benchmark, deterministic, reload_dataloaders_every_n_epochs, auto_lr_find, replace_sampler_ddp, detect_anomaly, auto_scale_batch_size, prepare_data_per_node, plugins, amp_backend, amp_level, move_metrics_to_cpu, multiple_trainloader_mode, stochastic_weight_avg, terminate_on_nan)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39m# init connectors\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector \u001b[39m=\u001b[39m DataConnector(\u001b[39mself\u001b[39m, multiple_trainloader_mode)\n\u001b[0;32m--> 485\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_connector \u001b[39m=\u001b[39m AcceleratorConnector(\n\u001b[1;32m    486\u001b[0m     num_processes\u001b[39m=\u001b[39;49mnum_processes,\n\u001b[1;32m    487\u001b[0m     devices\u001b[39m=\u001b[39;49mdevices,\n\u001b[1;32m    488\u001b[0m     tpu_cores\u001b[39m=\u001b[39;49mtpu_cores,\n\u001b[1;32m    489\u001b[0m     ipus\u001b[39m=\u001b[39;49mipus,\n\u001b[1;32m    490\u001b[0m     accelerator\u001b[39m=\u001b[39;49maccelerator,\n\u001b[1;32m    491\u001b[0m     strategy\u001b[39m=\u001b[39;49mstrategy,\n\u001b[1;32m    492\u001b[0m     gpus\u001b[39m=\u001b[39;49mgpus,\n\u001b[1;32m    493\u001b[0m     num_nodes\u001b[39m=\u001b[39;49mnum_nodes,\n\u001b[1;32m    494\u001b[0m     sync_batchnorm\u001b[39m=\u001b[39;49msync_batchnorm,\n\u001b[1;32m    495\u001b[0m     benchmark\u001b[39m=\u001b[39;49mbenchmark,\n\u001b[1;32m    496\u001b[0m     replace_sampler_ddp\u001b[39m=\u001b[39;49mreplace_sampler_ddp,\n\u001b[1;32m    497\u001b[0m     deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[1;32m    498\u001b[0m     auto_select_gpus\u001b[39m=\u001b[39;49mauto_select_gpus,\n\u001b[1;32m    499\u001b[0m     precision\u001b[39m=\u001b[39;49mprecision,\n\u001b[1;32m    500\u001b[0m     amp_type\u001b[39m=\u001b[39;49mamp_backend,\n\u001b[1;32m    501\u001b[0m     amp_level\u001b[39m=\u001b[39;49mamp_level,\n\u001b[1;32m    502\u001b[0m     plugins\u001b[39m=\u001b[39;49mplugins,\n\u001b[1;32m    503\u001b[0m )\n\u001b[1;32m    504\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logger_connector \u001b[39m=\u001b[39m LoggerConnector(\u001b[39mself\u001b[39m, log_gpu_memory)\n\u001b[1;32m    505\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_connector \u001b[39m=\u001b[39m CallbackConnector(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:217\u001b[0m, in \u001b[0;36mAcceleratorConnector.__init__\u001b[0;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, amp_type, amp_level, sync_batchnorm, benchmark, replace_sampler_ddp, deterministic, auto_select_gpus, num_processes, tpu_cores, ipus, gpus)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_and_init_precision()\n\u001b[1;32m    216\u001b[0m \u001b[39m# 6. Instantiate Strategy - Part 2\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lazy_init_strategy()\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:788\u001b[0m, in \u001b[0;36mAcceleratorConnector._lazy_init_strategy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m \u001b[39mimport\u001b[39;00m _IS_INTERACTIVE\n\u001b[1;32m    787\u001b[0m \u001b[39mif\u001b[39;00m _IS_INTERACTIVE \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mis_interactive_compatible:\n\u001b[0;32m--> 788\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\n\u001b[1;32m    789\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`Trainer(strategy=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mstrategy_name\u001b[39m!r}\u001b[39;00m\u001b[39m)` or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    790\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m `Trainer(accelerator=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mstrategy_name\u001b[39m!r}\u001b[39;00m\u001b[39m)` is not compatible with an interactive\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    791\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m environment. Run your code as a script, or choose one of the compatible strategies:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    792\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Trainer(strategy=None|\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m|\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(_StrategyType\u001b[39m.\u001b[39minteractive_compatible_types())\u001b[39m}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    793\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m In case you are spawning processes yourself, make sure to include the Trainer\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    794\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m creation inside the worker function.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    795\u001b[0m     )\n\u001b[1;32m    797\u001b[0m \u001b[39m# TODO: should be moved to _check_strategy_and_fallback().\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[39m# Current test check precision first, so keep this check here to meet error order\u001b[39;00m\n\u001b[1;32m    799\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator, TPUAccelerator) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m    800\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy, (SingleTPUStrategy, TPUSpawnStrategy)\n\u001b[1;32m    801\u001b[0m ):\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: `Trainer(strategy='ddp')` or `Trainer(accelerator='ddp')` is not compatible with an interactive environment. Run your code as a script, or choose one of the compatible strategies: Trainer(strategy=None|dp|tpu_spawn). In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function."
     ]
    }
   ],
   "source": [
    "cwd=os.getcwd()\n",
    "model, result = train_node_classifier(cur_dir=cwd, model_name=\"nonlinear NCEM\",data=data,c_hidden=30,num_layers=2,dp_rate=0.1)\n",
    "\n",
    "print_results(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('gnn': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42fc222dfbda169bc18a654c374e8265fec58846589cd1da63abc2a574b12f52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
