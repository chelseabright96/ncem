{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chels/anaconda3/envs/gnn/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import squidpy as sq\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data, LightningNodeData\n",
    "import torch_sparse\n",
    "import torch_geometric.nn as geom_nn\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sq.datasets.mibitof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3309x36 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 119124 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset \n",
    "adata = sq.datasets.imc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 08:55:01.233609: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-26 08:55:01.233730: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from dataset import HartmannWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HartmannWrapper(\"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1338"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63747\n"
     ]
    }
   ],
   "source": [
    "tot_nodes=0\n",
    "for i in range(len(dataset)):\n",
    "    tot_nodes+=dataset[i].num_nodes\n",
    "\n",
    "print(tot_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=58, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[63747, 8], edge_index=[2, 332512], y=[63747, 36], sf=[63747], batch=[63747], ptr=[59])\n"
     ]
    }
   ],
   "source": [
    "for batch in loader:\n",
    "    data=batch\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.transforms import RandomLinkSplit, RandomNodeSplit\n",
    "transform = RandomNodeSplit()\n",
    "data = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[63747, 8], edge_index=[2, 332512], y=[63747, 36], sf=[63747], batch=[63747], ptr=[59], train_mask=[63747], val_mask=[63747], test_mask=[63747])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([62247, 8])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = RandomLinkSplit(is_undirected=True)\n",
    "train, val, test = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[63747, 8], edge_index=[2, 232760], y=[63747, 36], sf=[63747], batch=[63747], ptr=[59], edge_label=[232760], edge_label_index=[2, 232760])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.x[val.train_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.long().nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(62247)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  324],\n",
       "        [  498],\n",
       "        [  762],\n",
       "        [  822],\n",
       "        [ 1171],\n",
       "        [ 1262],\n",
       "        [ 1475],\n",
       "        [ 1537],\n",
       "        [ 1856],\n",
       "        [ 1925],\n",
       "        [ 2147],\n",
       "        [ 2193],\n",
       "        [ 2278],\n",
       "        [ 2280],\n",
       "        [ 2492],\n",
       "        [ 2512],\n",
       "        [ 2712],\n",
       "        [ 2789],\n",
       "        [ 3030],\n",
       "        [ 3207],\n",
       "        [ 3919],\n",
       "        [ 3970],\n",
       "        [ 4082],\n",
       "        [ 4265],\n",
       "        [ 4308],\n",
       "        [ 4607],\n",
       "        [ 4631],\n",
       "        [ 4822],\n",
       "        [ 5025],\n",
       "        [ 5216],\n",
       "        [ 5543],\n",
       "        [ 5584],\n",
       "        [ 5737],\n",
       "        [ 5970],\n",
       "        [ 6003],\n",
       "        [ 6076],\n",
       "        [ 6279],\n",
       "        [ 6415],\n",
       "        [ 6483],\n",
       "        [ 6511],\n",
       "        [ 6671],\n",
       "        [ 6699],\n",
       "        [ 7066],\n",
       "        [ 7283],\n",
       "        [ 7367],\n",
       "        [ 7397],\n",
       "        [ 7416],\n",
       "        [ 7541],\n",
       "        [ 7726],\n",
       "        [ 7827],\n",
       "        [ 8177],\n",
       "        [ 8192],\n",
       "        [ 8271],\n",
       "        [ 8307],\n",
       "        [ 8799],\n",
       "        [ 8971],\n",
       "        [ 8983],\n",
       "        [ 9050],\n",
       "        [ 9150],\n",
       "        [ 9380],\n",
       "        [ 9549],\n",
       "        [ 9578],\n",
       "        [ 9861],\n",
       "        [ 9900],\n",
       "        [10000],\n",
       "        [10105],\n",
       "        [10407],\n",
       "        [10451],\n",
       "        [10595],\n",
       "        [10796],\n",
       "        [10957],\n",
       "        [10965],\n",
       "        [11087],\n",
       "        [11251],\n",
       "        [11367],\n",
       "        [11458],\n",
       "        [11479],\n",
       "        [11556],\n",
       "        [11675],\n",
       "        [11745],\n",
       "        [12003],\n",
       "        [12075],\n",
       "        [12392],\n",
       "        [12405],\n",
       "        [12488],\n",
       "        [12585],\n",
       "        [12594],\n",
       "        [12741],\n",
       "        [12911],\n",
       "        [12994],\n",
       "        [13474],\n",
       "        [13493],\n",
       "        [13546],\n",
       "        [13640],\n",
       "        [13935],\n",
       "        [14193],\n",
       "        [14257],\n",
       "        [14260],\n",
       "        [14325],\n",
       "        [14492],\n",
       "        [14910],\n",
       "        [15185],\n",
       "        [15518],\n",
       "        [15685],\n",
       "        [15762],\n",
       "        [15801],\n",
       "        [16091],\n",
       "        [16131],\n",
       "        [16140],\n",
       "        [16175],\n",
       "        [16316],\n",
       "        [16353],\n",
       "        [16357],\n",
       "        [16371],\n",
       "        [16556],\n",
       "        [16594],\n",
       "        [16691],\n",
       "        [16725],\n",
       "        [16843],\n",
       "        [16955],\n",
       "        [16959],\n",
       "        [16961],\n",
       "        [17116],\n",
       "        [17419],\n",
       "        [17482],\n",
       "        [17489],\n",
       "        [17553],\n",
       "        [17579],\n",
       "        [17581],\n",
       "        [17747],\n",
       "        [17910],\n",
       "        [17966],\n",
       "        [18008],\n",
       "        [18012],\n",
       "        [18091],\n",
       "        [18173],\n",
       "        [18219],\n",
       "        [18278],\n",
       "        [18400],\n",
       "        [18412],\n",
       "        [18829],\n",
       "        [18871],\n",
       "        [19031],\n",
       "        [19083],\n",
       "        [19179],\n",
       "        [19348],\n",
       "        [19656],\n",
       "        [19784],\n",
       "        [19900],\n",
       "        [20076],\n",
       "        [20238],\n",
       "        [20306],\n",
       "        [20625],\n",
       "        [20640],\n",
       "        [20682],\n",
       "        [20729],\n",
       "        [20866],\n",
       "        [21089],\n",
       "        [21451],\n",
       "        [21893],\n",
       "        [21913],\n",
       "        [21924],\n",
       "        [22017],\n",
       "        [22262],\n",
       "        [22452],\n",
       "        [22491],\n",
       "        [22638],\n",
       "        [22740],\n",
       "        [22751],\n",
       "        [22825],\n",
       "        [22873],\n",
       "        [22922],\n",
       "        [23062],\n",
       "        [23146],\n",
       "        [23286],\n",
       "        [23315],\n",
       "        [23476],\n",
       "        [23512],\n",
       "        [23586],\n",
       "        [23608],\n",
       "        [23642],\n",
       "        [23657],\n",
       "        [23709],\n",
       "        [23763],\n",
       "        [23817],\n",
       "        [23865],\n",
       "        [23975],\n",
       "        [23976],\n",
       "        [24243],\n",
       "        [24350],\n",
       "        [24556],\n",
       "        [24560],\n",
       "        [24666],\n",
       "        [24672],\n",
       "        [24894],\n",
       "        [24899],\n",
       "        [24941],\n",
       "        [24974],\n",
       "        [25115],\n",
       "        [25204],\n",
       "        [25532],\n",
       "        [25648],\n",
       "        [25750],\n",
       "        [25782],\n",
       "        [25923],\n",
       "        [25953],\n",
       "        [25984],\n",
       "        [26228],\n",
       "        [26497],\n",
       "        [26568],\n",
       "        [26674],\n",
       "        [26748],\n",
       "        [26835],\n",
       "        [26869],\n",
       "        [27060],\n",
       "        [27201],\n",
       "        [27267],\n",
       "        [27321],\n",
       "        [27521],\n",
       "        [27533],\n",
       "        [27603],\n",
       "        [27611],\n",
       "        [27625],\n",
       "        [27855],\n",
       "        [27876],\n",
       "        [28335],\n",
       "        [28743],\n",
       "        [28748],\n",
       "        [28879],\n",
       "        [29006],\n",
       "        [29072],\n",
       "        [29190],\n",
       "        [29387],\n",
       "        [29666],\n",
       "        [29684],\n",
       "        [29902],\n",
       "        [30231],\n",
       "        [30264],\n",
       "        [30434],\n",
       "        [30456],\n",
       "        [30466],\n",
       "        [30532],\n",
       "        [30549],\n",
       "        [30857],\n",
       "        [30890],\n",
       "        [30931],\n",
       "        [31007],\n",
       "        [31065],\n",
       "        [31132],\n",
       "        [31173],\n",
       "        [31176],\n",
       "        [31347],\n",
       "        [31438],\n",
       "        [31540],\n",
       "        [31563],\n",
       "        [31660],\n",
       "        [31871],\n",
       "        [32002],\n",
       "        [32007],\n",
       "        [32194],\n",
       "        [32362],\n",
       "        [32527],\n",
       "        [32708],\n",
       "        [32776],\n",
       "        [32855],\n",
       "        [33173],\n",
       "        [33181],\n",
       "        [33210],\n",
       "        [33250],\n",
       "        [33377],\n",
       "        [33448],\n",
       "        [33603],\n",
       "        [33615],\n",
       "        [33741],\n",
       "        [34028],\n",
       "        [34493],\n",
       "        [34516],\n",
       "        [34653],\n",
       "        [34667],\n",
       "        [34719],\n",
       "        [34737],\n",
       "        [34767],\n",
       "        [34780],\n",
       "        [34861],\n",
       "        [35335],\n",
       "        [35492],\n",
       "        [35641],\n",
       "        [35650],\n",
       "        [35719],\n",
       "        [35770],\n",
       "        [35901],\n",
       "        [35903],\n",
       "        [36016],\n",
       "        [36083],\n",
       "        [36093],\n",
       "        [36115],\n",
       "        [36170],\n",
       "        [36197],\n",
       "        [36312],\n",
       "        [36440],\n",
       "        [36501],\n",
       "        [36509],\n",
       "        [36540],\n",
       "        [36729],\n",
       "        [36734],\n",
       "        [36783],\n",
       "        [36966],\n",
       "        [36994],\n",
       "        [37170],\n",
       "        [37413],\n",
       "        [37439],\n",
       "        [37481],\n",
       "        [37620],\n",
       "        [37656],\n",
       "        [37951],\n",
       "        [38104],\n",
       "        [38142],\n",
       "        [38279],\n",
       "        [38321],\n",
       "        [38622],\n",
       "        [38845],\n",
       "        [38857],\n",
       "        [38973],\n",
       "        [39068],\n",
       "        [39228],\n",
       "        [39247],\n",
       "        [39372],\n",
       "        [39393],\n",
       "        [39650],\n",
       "        [39798],\n",
       "        [39939],\n",
       "        [40085],\n",
       "        [40245],\n",
       "        [40483],\n",
       "        [40608],\n",
       "        [40638],\n",
       "        [40671],\n",
       "        [40680],\n",
       "        [40732],\n",
       "        [40869],\n",
       "        [40944],\n",
       "        [40954],\n",
       "        [41527],\n",
       "        [41532],\n",
       "        [41810],\n",
       "        [42612],\n",
       "        [42815],\n",
       "        [42859],\n",
       "        [43086],\n",
       "        [43113],\n",
       "        [43358],\n",
       "        [43547],\n",
       "        [43600],\n",
       "        [43918],\n",
       "        [44061],\n",
       "        [44071],\n",
       "        [44320],\n",
       "        [44500],\n",
       "        [44545],\n",
       "        [44589],\n",
       "        [44860],\n",
       "        [44932],\n",
       "        [44937],\n",
       "        [44958],\n",
       "        [45015],\n",
       "        [45048],\n",
       "        [45209],\n",
       "        [45216],\n",
       "        [45631],\n",
       "        [45638],\n",
       "        [45726],\n",
       "        [45874],\n",
       "        [46210],\n",
       "        [46408],\n",
       "        [46428],\n",
       "        [46429],\n",
       "        [46464],\n",
       "        [46519],\n",
       "        [46593],\n",
       "        [46802],\n",
       "        [46903],\n",
       "        [46914],\n",
       "        [46917],\n",
       "        [47193],\n",
       "        [47308],\n",
       "        [47683],\n",
       "        [47819],\n",
       "        [47904],\n",
       "        [48263],\n",
       "        [48333],\n",
       "        [48340],\n",
       "        [48367],\n",
       "        [48379],\n",
       "        [48401],\n",
       "        [48427],\n",
       "        [48430],\n",
       "        [48753],\n",
       "        [48756],\n",
       "        [48846],\n",
       "        [48893],\n",
       "        [48897],\n",
       "        [48947],\n",
       "        [49040],\n",
       "        [49767],\n",
       "        [49889],\n",
       "        [50103],\n",
       "        [50106],\n",
       "        [50210],\n",
       "        [50235],\n",
       "        [50374],\n",
       "        [50408],\n",
       "        [50460],\n",
       "        [50612],\n",
       "        [50996],\n",
       "        [51404],\n",
       "        [51510],\n",
       "        [51808],\n",
       "        [52183],\n",
       "        [52502],\n",
       "        [52528],\n",
       "        [52616],\n",
       "        [52700],\n",
       "        [52778],\n",
       "        [52794],\n",
       "        [52938],\n",
       "        [53010],\n",
       "        [53161],\n",
       "        [53200],\n",
       "        [53263],\n",
       "        [53948],\n",
       "        [54013],\n",
       "        [54265],\n",
       "        [54366],\n",
       "        [55001],\n",
       "        [55228],\n",
       "        [55275],\n",
       "        [55853],\n",
       "        [56227],\n",
       "        [56281],\n",
       "        [56299],\n",
       "        [56432],\n",
       "        [56526],\n",
       "        [56781],\n",
       "        [57037],\n",
       "        [57076],\n",
       "        [57078],\n",
       "        [57284],\n",
       "        [57292],\n",
       "        [57322],\n",
       "        [57482],\n",
       "        [57492],\n",
       "        [58243],\n",
       "        [58740],\n",
       "        [58800],\n",
       "        [58932],\n",
       "        [59126],\n",
       "        [59131],\n",
       "        [59132],\n",
       "        [59138],\n",
       "        [59224],\n",
       "        [59242],\n",
       "        [59412],\n",
       "        [59527],\n",
       "        [59652],\n",
       "        [59671],\n",
       "        [59767],\n",
       "        [59782],\n",
       "        [59796],\n",
       "        [59878],\n",
       "        [59921],\n",
       "        [60225],\n",
       "        [60227],\n",
       "        [60377],\n",
       "        [60567],\n",
       "        [60580],\n",
       "        [60786],\n",
       "        [60870],\n",
       "        [61079],\n",
       "        [61168],\n",
       "        [61221],\n",
       "        [61234],\n",
       "        [61258],\n",
       "        [61370],\n",
       "        [61393],\n",
       "        [61429],\n",
       "        [61529],\n",
       "        [61530],\n",
       "        [61760],\n",
       "        [61830],\n",
       "        [61890],\n",
       "        [62052],\n",
       "        [62238],\n",
       "        [62468],\n",
       "        [62483],\n",
       "        [62837],\n",
       "        [63076],\n",
       "        [63185],\n",
       "        [63198],\n",
       "        [63199],\n",
       "        [63319]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.val_mask.long().nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = geom_nn.GCNConv(dataset.num_node_features, dataset.y.shape[1])\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNCEM(pl.LightningModule):\n",
    "    def __init__(self, **model_kwargs):\n",
    "        super().__init__()\n",
    "        # Saving hyperparameters\n",
    "        self.save_hyperparameters(model_kwargs)\n",
    "\n",
    "        self.model_mu = GCN(\n",
    "            in_channels=self.hparams.in_channels,\n",
    "            hidden_dims=self.hparams.encoder_hidden_dims,\n",
    "            out_channels=self.hparams.latent_dim,\n",
    "        )\n",
    "\n",
    "        self.model_sigma = GCN(\n",
    "            in_channels=self.hparams.in_channels,\n",
    "            hidden_dims=self.hparams.encoder_hidden_dims,\n",
    "            out_channels=self.hparams.latent_dim,\n",
    "        )\n",
    "\n",
    "        self.loss_module = nn.GaussianNLLLoss(eps=1e-5)\n",
    "\n",
    "        def init_weights(m):\n",
    "            if isinstance(m, geom_nn.GCNConv):\n",
    "                pass\n",
    "                # TODO: how to init weights of GNN's?\n",
    "                # torch.nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                # m.bias.data.fill_(0.01)\n",
    "\n",
    "\n",
    "        self.model_mu.apply(init_weights)\n",
    "        self.model_sigma.apply(init_weights)\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        sigma = self.model_mu(x, edge_index)\n",
    "        mu = self.model_sigma(x, edge_index)\n",
    "        return mu, sigma\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # We use SGD here, but Adam works as well\n",
    "        optimizer = optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=0.05,#self.hparams[\"lr\"],\n",
    "            weight_decay=0#self.hparams[\"weight_decay\"],\n",
    "        )\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, _):\n",
    "        mu, sigma = self.forward(batch)\n",
    "        loss = self.loss_module(mu, batch.y, sigma)\n",
    "        self.log('train_loss', loss, batch_size=batch.batch_size)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, _):\n",
    "        mu, sigma = self.forward(batch)\n",
    "        val_loss = self.loss_module(mu, batch.y, sigma)\n",
    "        val_r2_score = r2_score(batch.y.cpu(), mu.cpu())\n",
    "        self.log('val_r2_score', val_r2_score, batch_size=batch.batch_size, prog_bar=True)\n",
    "        self.log('val_loss', val_loss, batch_size=batch.batch_size, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, _):\n",
    "        mu, sigma = self.forward(batch)\n",
    "        self.log('test_loss', loss, batch_size=batch.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get adjacency matrix\n",
    "sq.gr.spatial_neighbors(adata, coord_type=\"generic\")\n",
    "A=adata.obsp['spatial_connectivities']\n",
    "\n",
    "#Get features of nodes \n",
    "X=adata.obs\n",
    "X=pd.get_dummies(X)\n",
    "X=X.to_numpy()\n",
    "X=torch.tensor(X)\n",
    "\n",
    "#Get labels of nodes\n",
    "Y=adata.X\n",
    "Y=torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Acoo = A.tocoo()\n",
    "A_sparse = torch.sparse.FloatTensor(torch.LongTensor([Acoo.row.tolist(), Acoo.col.tolist()]),\n",
    "                              torch.FloatTensor(Acoo.data)).coalesce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(x=X,edge_index=A_sparse.indices(), y=Y, train_mask=torch.arange(A.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[4668, 11], edge_index=[2, 28008], y=[4668, 34], train_mask=[4668])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.GaussianNLLLoss()\n",
    "input = torch.randn(5, 2, requires_grad=True)\n",
    "target = torch.randn(5, 2)\n",
    "var = torch.ones(5, 2, requires_grad=True) #heteroscedastic\n",
    "output = loss(input, target, var)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = NeighborLoader(\n",
    "    data,\n",
    "    # Sample 30 neighbors for each node for 2 iterations\n",
    "    num_neighbors=[30] * 2,\n",
    "    # Use a batch size of 128 for sampling training nodes\n",
    "    batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning_loader = LightningNodeData(data, data.train_mask, loader='neighbor',\n",
    "                                   num_neighbors=[30] * 2, batch_size=128,\n",
    "                                   num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[292, 11], edge_index=[2, 1254], y=[292, 34], train_mask=[292], batch_size=128)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data ## this is one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(result_dict):\n",
    "    if \"train\" in result_dict:\n",
    "        print(f\"Train loss: {result_dict['train']}\")\n",
    "    if \"val\" in result_dict:\n",
    "        print(f\"Val loss:   {result_dict['val']}\")\n",
    "    print(f\"Test loss:  {result_dict['test']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_node_classifier(cur_dir, model_name, data, **model_kwargs):\n",
    "    pl.seed_everything(42)\n",
    "    node_data_loader = lightning_loader \n",
    "    strategy = pl.strategies.DDPStrategy(find_unused_parameters=False)\n",
    "    '''NeighborLoader(\n",
    "    data,\n",
    "    # Sample 30 neighbors for each node for 2 iterations\n",
    "    num_neighbors=[30] * 2,\n",
    "    # Use a batch size of 128 for sampling training nodes\n",
    "    batch_size=128)'''\n",
    "\n",
    "    CHECKPOINT_PATH = cur_dir + \"checkpoints\"\n",
    "\n",
    "    # Create a PyTorch Lightning trainer with the generation callback\n",
    "    root_dir = os.path.join(CHECKPOINT_PATH, model_name)\n",
    "    os.makedirs(root_dir, exist_ok=True)\n",
    "    trainer = pl.Trainer(strategy=strategy, default_root_dir=root_dir, callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"min\", monitor=\"val_loss\")],\n",
    "                         max_epochs=200,\n",
    "                         progress_bar_refresh_rate=0) # 0 because epoch size is 1\n",
    "\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, f\"{model_name}.ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(\"Found pretrained model, loading...\")\n",
    "        model = NodeLevelGNN.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        pl.seed_everything()\n",
    "        model = NodeLevelGNN(model_name=model_name, c_in=data.x.shape[1], c_out=data.y.shape[1], **model_kwargs)\n",
    "        trainer.fit(model, node_data_loader)\n",
    "        model = NodeLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "\n",
    "    # Test best model on the test set\n",
    "    test_result = trainer.test(model, node_data_loader, verbose=False)\n",
    "    batch = next(iter(node_data_loader))\n",
    "    batch = batch.to(model.device)\n",
    "    train_loss = model.forward(batch, mode=\"train\")\n",
    "    val_loss = model.forward(batch, mode=\"val\")\n",
    "    result = {\"train\": train_loss,\n",
    "              \"val\": val_loss,\n",
    "              \"test\": test_result['test_loss']}\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "`Trainer(strategy='ddp')` or `Trainer(accelerator='ddp')` is not compatible with an interactive environment. Run your code as a script, or choose one of the compatible strategies: Trainer(strategy=None|dp|tpu_spawn). In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb#ch0000011vscode-remote?line=0'>1</a>\u001b[0m cwd\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mgetcwd()\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb#ch0000011vscode-remote?line=1'>2</a>\u001b[0m model, result \u001b[39m=\u001b[39m train_node_classifier(cur_dir\u001b[39m=\u001b[39;49mcwd, model_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mnonlinear NCEM\u001b[39;49m\u001b[39m\"\u001b[39;49m,data\u001b[39m=\u001b[39;49mdata,c_hidden\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,num_layers\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,dp_rate\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb#ch0000011vscode-remote?line=3'>4</a>\u001b[0m print_results(result)\n",
      "\u001b[1;32m/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb Cell 12\u001b[0m in \u001b[0;36mtrain_node_classifier\u001b[0;34m(cur_dir, model_name, data, **model_kwargs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb#ch0000011vscode-remote?line=14'>15</a>\u001b[0m root_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(CHECKPOINT_PATH, model_name)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb#ch0000011vscode-remote?line=15'>16</a>\u001b[0m os\u001b[39m.\u001b[39mmakedirs(root_dir, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb#ch0000011vscode-remote?line=16'>17</a>\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39;49mTrainer(strategy\u001b[39m=\u001b[39;49mstrategy, default_root_dir\u001b[39m=\u001b[39;49mroot_dir, callbacks\u001b[39m=\u001b[39;49m[ModelCheckpoint(save_weights_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmin\u001b[39;49m\u001b[39m\"\u001b[39;49m, monitor\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mval_loss\u001b[39;49m\u001b[39m\"\u001b[39;49m)],\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb#ch0000011vscode-remote?line=17'>18</a>\u001b[0m                      max_epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb#ch0000011vscode-remote?line=18'>19</a>\u001b[0m                      progress_bar_refresh_rate\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m) \u001b[39m# 0 because epoch size is 1\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb#ch0000011vscode-remote?line=21'>22</a>\u001b[0m \u001b[39m# Check whether pretrained model exists. If yes, load it and skip training\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/chels/TheisLab/repos/ncem/ncem/gnn_gpu.ipynb#ch0000011vscode-remote?line=22'>23</a>\u001b[0m pretrained_filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(CHECKPOINT_PATH, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m.ckpt\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.9/site-packages/pytorch_lightning/utilities/argparse.py:339\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mlist\u001b[39m(env_variables\u001b[39m.\u001b[39mitems()) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mitems()))\n\u001b[1;32m    338\u001b[0m \u001b[39m# all args were already moved to kwargs\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:485\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, logger, checkpoint_callback, enable_checkpointing, callbacks, default_root_dir, gradient_clip_val, gradient_clip_algorithm, process_position, num_nodes, num_processes, devices, gpus, auto_select_gpus, tpu_cores, ipus, log_gpu_memory, progress_bar_refresh_rate, enable_progress_bar, overfit_batches, track_grad_norm, check_val_every_n_epoch, fast_dev_run, accumulate_grad_batches, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, val_check_interval, flush_logs_every_n_steps, log_every_n_steps, accelerator, strategy, sync_batchnorm, precision, enable_model_summary, weights_summary, weights_save_path, num_sanity_val_steps, resume_from_checkpoint, profiler, benchmark, deterministic, reload_dataloaders_every_n_epochs, auto_lr_find, replace_sampler_ddp, detect_anomaly, auto_scale_batch_size, prepare_data_per_node, plugins, amp_backend, amp_level, move_metrics_to_cpu, multiple_trainloader_mode, stochastic_weight_avg, terminate_on_nan)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39m# init connectors\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector \u001b[39m=\u001b[39m DataConnector(\u001b[39mself\u001b[39m, multiple_trainloader_mode)\n\u001b[0;32m--> 485\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_connector \u001b[39m=\u001b[39m AcceleratorConnector(\n\u001b[1;32m    486\u001b[0m     num_processes\u001b[39m=\u001b[39;49mnum_processes,\n\u001b[1;32m    487\u001b[0m     devices\u001b[39m=\u001b[39;49mdevices,\n\u001b[1;32m    488\u001b[0m     tpu_cores\u001b[39m=\u001b[39;49mtpu_cores,\n\u001b[1;32m    489\u001b[0m     ipus\u001b[39m=\u001b[39;49mipus,\n\u001b[1;32m    490\u001b[0m     accelerator\u001b[39m=\u001b[39;49maccelerator,\n\u001b[1;32m    491\u001b[0m     strategy\u001b[39m=\u001b[39;49mstrategy,\n\u001b[1;32m    492\u001b[0m     gpus\u001b[39m=\u001b[39;49mgpus,\n\u001b[1;32m    493\u001b[0m     num_nodes\u001b[39m=\u001b[39;49mnum_nodes,\n\u001b[1;32m    494\u001b[0m     sync_batchnorm\u001b[39m=\u001b[39;49msync_batchnorm,\n\u001b[1;32m    495\u001b[0m     benchmark\u001b[39m=\u001b[39;49mbenchmark,\n\u001b[1;32m    496\u001b[0m     replace_sampler_ddp\u001b[39m=\u001b[39;49mreplace_sampler_ddp,\n\u001b[1;32m    497\u001b[0m     deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[1;32m    498\u001b[0m     auto_select_gpus\u001b[39m=\u001b[39;49mauto_select_gpus,\n\u001b[1;32m    499\u001b[0m     precision\u001b[39m=\u001b[39;49mprecision,\n\u001b[1;32m    500\u001b[0m     amp_type\u001b[39m=\u001b[39;49mamp_backend,\n\u001b[1;32m    501\u001b[0m     amp_level\u001b[39m=\u001b[39;49mamp_level,\n\u001b[1;32m    502\u001b[0m     plugins\u001b[39m=\u001b[39;49mplugins,\n\u001b[1;32m    503\u001b[0m )\n\u001b[1;32m    504\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logger_connector \u001b[39m=\u001b[39m LoggerConnector(\u001b[39mself\u001b[39m, log_gpu_memory)\n\u001b[1;32m    505\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_connector \u001b[39m=\u001b[39m CallbackConnector(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:217\u001b[0m, in \u001b[0;36mAcceleratorConnector.__init__\u001b[0;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, amp_type, amp_level, sync_batchnorm, benchmark, replace_sampler_ddp, deterministic, auto_select_gpus, num_processes, tpu_cores, ipus, gpus)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_and_init_precision()\n\u001b[1;32m    216\u001b[0m \u001b[39m# 6. Instantiate Strategy - Part 2\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lazy_init_strategy()\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:788\u001b[0m, in \u001b[0;36mAcceleratorConnector._lazy_init_strategy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_lightning\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutilities\u001b[39;00m \u001b[39mimport\u001b[39;00m _IS_INTERACTIVE\n\u001b[1;32m    787\u001b[0m \u001b[39mif\u001b[39;00m _IS_INTERACTIVE \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mis_interactive_compatible:\n\u001b[0;32m--> 788\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\n\u001b[1;32m    789\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`Trainer(strategy=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mstrategy_name\u001b[39m!r}\u001b[39;00m\u001b[39m)` or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    790\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m `Trainer(accelerator=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mstrategy_name\u001b[39m!r}\u001b[39;00m\u001b[39m)` is not compatible with an interactive\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    791\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m environment. Run your code as a script, or choose one of the compatible strategies:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    792\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Trainer(strategy=None|\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m|\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(_StrategyType\u001b[39m.\u001b[39minteractive_compatible_types())\u001b[39m}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    793\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m In case you are spawning processes yourself, make sure to include the Trainer\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    794\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m creation inside the worker function.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    795\u001b[0m     )\n\u001b[1;32m    797\u001b[0m \u001b[39m# TODO: should be moved to _check_strategy_and_fallback().\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[39m# Current test check precision first, so keep this check here to meet error order\u001b[39;00m\n\u001b[1;32m    799\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator, TPUAccelerator) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m    800\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy, (SingleTPUStrategy, TPUSpawnStrategy)\n\u001b[1;32m    801\u001b[0m ):\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: `Trainer(strategy='ddp')` or `Trainer(accelerator='ddp')` is not compatible with an interactive environment. Run your code as a script, or choose one of the compatible strategies: Trainer(strategy=None|dp|tpu_spawn). In case you are spawning processes yourself, make sure to include the Trainer creation inside the worker function."
     ]
    }
   ],
   "source": [
    "cwd=os.getcwd()\n",
    "model, result = train_node_classifier(cur_dir=cwd, model_name=\"nonlinear NCEM\",data=data,c_hidden=30,num_layers=2,dp_rate=0.1)\n",
    "\n",
    "print_results(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('gnn': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42fc222dfbda169bc18a654c374e8265fec58846589cd1da63abc2a574b12f52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
